# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# see kafka.producer.ProducerConfig for more details

############################# Producer Basics #############################

# list of brokers used for bootstrapping knowledge about the rest of the cluster
# format: host1:port1,host2:port2 ...
bootstrap.servers={{ getenv "DST_BOOTSTRAP_SERVERS" }}
client.id={{ getenv "CONSUMER_GROUP_ID" }}

# name of the partitioner class for partitioning events; default partition spreads data randomly
#partitioner.class=

# specifies whether the messages are sent asynchronously (async) or synchronously (sync)
# NOT SUPPORTED
#producer.type=async

# specify the compression codec for all data generated: none, gzip, snappy, lz4.
# the old config values work as well: 0, 1, 2, 3 for none, gzip, snappy, lz4, respectively
# NOT SUPPORTED
#compression.codec=snappy
# CORRECT PROPERT?Y
compression.type={{ getenv "PROD_COMPRESSION_TYPE" }}

# message encoder
# NOT SUPPORTED
# serializer.class=kafka.serializer.DefaultEncoder
key.serializer=org.apache.kafka.common.serialization.ByteArraySerializer
value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer

# allow topic level compression
#compressed.topics=

# Alias for queue.buffering.max.ms: Delay in milliseconds to wait for messages in the producer queue to accumulate before constructing message batches (MessageSets) to transmit to brokers. A higher value allows larger and more effective (less overhead, improved compression) batches of messages to accumulate at the expense of increased message delivery latency.
linger.ms={{ getenv "PROD_LINGER_MS" }}

############################# Async Producer #############################
# maximum time, in milliseconds, for buffering data on the producer queue
# NOT SUPPORTED
#queue.buffering.max.ms={{ getenv "PROD_QUEUE_BUFFERING_MAX_MS" }}

# the maximum size of the blocking queue for buffering on the producer
# NOT SUPPORTED
#queue.buffering.max.messages={{ getenv "PROD_QUEUE_BUFFERING_MAX_MESSAGES" }}

# Timeout for event enqueue:
# 0: events will be enqueued immediately or dropped if the queue is full
# -ve: enqueue will block indefinitely if the queue is full
# +ve: enqueue will block up to this many milliseconds if the queue is full
#queue.enqueue.timeout.ms=

# the number of messages batched at the producer
# NOT SUPPORTED
#batch.num.messages={{ getenv "PROD_BATCH_NUM_MESSAGES" }}

send.buffer.bytes={{ getenv "PROD_SEND_BUFFER_BYTES" }}

# The maximum number of unacknowledged requests the client will send on a single connection before blocking. Note that if this setting is set to be greater than 1 and there are failed sends, there is a risk of message re-ordering due to retries (i.e., if retries are enabled).
max.in.flight.requests.per.connection={{ getenv "PROD_MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION" }}

max.request.size={{ getenv "PROD_MAX_REQUEST_SIZE" }}
